# transformer
Masking primary practice

A primary Pytorch Implementation of Transformer:Attention is All You Need

